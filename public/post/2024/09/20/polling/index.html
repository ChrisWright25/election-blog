<!DOCTYPE html>
<html lang="en-us">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=4321&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Polling | Chris Wright&#39;s Election Blog</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">Polling</span></h1>
<h2 class="author">Chris Wright</h2>
<h2 class="date">2024/09/20</h2>
</div>

<main>
<img src="gallup.jpg" width="33%" height="33%" style="display: block; margin: auto;" />
<p>The picture above is of George Gallup. Gallup is considered to be the father of public opinion polling and founded the namesake polling organization, Gallup. Since Gallup revolutionized polling, it has been a mainstay when talking about elections. Although polls are widely conducted and a focal point of campaign news, the validity and accuracy of polls has always been in question. In the 1948 election, polls famously predicted a Dewey victory over Truman and more recently some polls underestimated the support for Trump in the 2016 election. These polling mishaps lead to one essential question: What makes a good poll?</p>
<h2 id="538-pollster-ratings">538 Pollster Ratings</h2>
<p>538 attempts to answer the question by giving each poll that it includes in its aggregation a <a href="https://projects.fivethirtyeight.com/pollster-ratings/">rating</a>. In the past this rating was on a scale from A+ to D-, but now the rating is on a scale from 0 to 3. According to 538&rsquo;s <a href="https://fivethirtyeight.com/methodology/how-our-pollster-ratings-work/">website</a> the rating takes into account several factors</p>
<ul>
<li>Simple error for polls (i.e., how far away the poll results are from the actual election margin).</li>
<li>How well other pollsters performed in the same races (i.e., whether this pollster is as good as, better than or worse than others).</li>
<li>Methodological quality (i.e., whether this pollster is conducting polls in accordance with professional standards).</li>
<li>Herding (i.e., whether this pollster appears to just be copying others’ results).</li>
</ul>
<h2 id="evaluating-the-ratings">Evaluating the Ratings</h2>
<p>Utilizing polls from the 2016 and 2020 election cycle (before the numeric pollster ratings) I analyzed the difference in polling ratings. For the analysis, I grouped the pollster ratings into three categories: A (A+, A, and A-), B (B+, B, and B-), and C (C+, C, and C-).</p>
<p>The first observation from this analysis is the large number of C rated polls compared to A and B rated polls. There are almost 1000 more polls in the C range than the A and B range. C polls also stand out on sample size. The mean sample size of C polls is 4x the mean of A polls. C polls also seem to have a more Democratic tilt, as they predict Democratic support 4 points higher than A and B polls on average. Lastly, C polls appear more prone to outliers as they have both a poll with a sample size of 88 and one with a 94% prediction.</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">Pollster Rating</th>
          <th style="text-align: left">Number of Polls</th>
          <th style="text-align: left">Mean Sample Size</th>
          <th style="text-align: left">Max Sample Size</th>
          <th style="text-align: left">Min Sample Size</th>
          <th style="text-align: left">Mean DEM prediction</th>
          <th style="text-align: left">Max Dem Prediction</th>
          <th style="text-align: left">Min Dem Prediction</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">A</td>
          <td style="text-align: left">2783</td>
          <td style="text-align: left">1122</td>
          <td style="text-align: left">5459</td>
          <td style="text-align: left">301</td>
          <td style="text-align: left">46.45</td>
          <td style="text-align: left">69.44</td>
          <td style="text-align: left">34.00</td>
      </tr>
      <tr>
          <td style="text-align: left">B</td>
          <td style="text-align: left">2323</td>
          <td style="text-align: left">2722</td>
          <td style="text-align: left">71789</td>
          <td style="text-align: left">201</td>
          <td style="text-align: left">46.12</td>
          <td style="text-align: left">64.00</td>
          <td style="text-align: left">20.00</td>
      </tr>
      <tr>
          <td style="text-align: left">C</td>
          <td style="text-align: left">3643</td>
          <td style="text-align: left">5043</td>
          <td style="text-align: left">42858</td>
          <td style="text-align: left">88</td>
          <td style="text-align: left">50.39</td>
          <td style="text-align: left">94.00</td>
          <td style="text-align: left">21.48</td>
      </tr>
  </tbody>
</table>
<p>Additionally, in an attempt to see accuracy over time, I plotted the average poll prediction for Democratic candidates. The dotted line represents the actual election outcome. Although the C polls have more range, they seem to get closer to the actual prediction as the election date is closer</p>
<p>Note: The dotted line is a sum of the 2016 and 2020 election since the dataset covers the 2016 and 2020 elections</p>
<img src="/post/2024/09/20/polling/index_files/figure-html/unnamed-chunk-4-1.png" width="672" />
<h2 id="predicting-based-on-the-ratings">Predicting Based on the Ratings</h2>
<p>Lastly, I used the A, B, and C polls to predict the 2024 election to see if there is any difference in the predictions. Before fitting the model, I subset it to only predictions for the Democratic party. Then I fit the model using the projected Democratic vote share and the actual election outcome in either 2016 or 2020. Lastly, I used 2024 polling data to predict based on the model. In future analysis, I would include older polls to have more data points; however, I was unable to find older polling data with the associated 538 pollster ratings.</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">Model</th>
          <th style="text-align: left">Predicted DEM Vote</th>
          <th style="text-align: left">R-squared</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">A</td>
          <td style="text-align: left">49.15%</td>
          <td style="text-align: left">0.2853</td>
      </tr>
      <tr>
          <td style="text-align: left">B</td>
          <td style="text-align: left">50.65%</td>
          <td style="text-align: left">0.0004535</td>
      </tr>
      <tr>
          <td style="text-align: left">C</td>
          <td style="text-align: left">50.53%</td>
          <td style="text-align: left">0.06187</td>
      </tr>
  </tbody>
</table>
<p>Ultimately, all of the models had pretty low R-squared values which means that they explain little of the variance in the data. However, the A prediction model had the best R-squared. The models also gave similar predictions and the B model gave the most support to Democrats. When all the models are combined, they predict that Democrats will capture <strong>50.1%</strong> of the vote in the 2024 election. According to my analysis, there is little variation in the prediction based on pollster ratings. However, the higher R-squared leads me to believe that A polls are better than lower rated ones.</p>

</main>

  <footer>
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex/dist/katex.min.css">
<script src="//cdn.jsdelivr.net/combine/npm/katex/dist/katex.min.js,npm/katex/dist/contrib/auto-render.min.js,npm/@xiee/utils/js/render-katex.js" defer></script>

<script src="//cdn.jsdelivr.net/npm/@xiee/utils/js/center-img.min.js" defer></script>

  
  <hr/>
  © Chris Wright 2024 | <a href="https://github.com/ChrisWright25/election-blog">Github</a>
  
  </footer>
  </body>
</html>

